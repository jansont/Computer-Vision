# -*- coding: utf-8 -*-
"""Assignment3-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kGokwIv2QrCqEHy-gYQVJH9kshkSa0NR

# Assignment 3: Classification with SVM and RF
Author: Theodore Janson - 260868223 <br>
Course: ECSE 415 <br>
Date: November 2nd, 2020
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2
from sklearn import svm
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier

# %matplotlib inline
from google.colab import drive
drive.mount('/content/drive')

#declaring data path
path = '/content/drive/My Drive/ECSE 415/Assignments/Assignment_3/'

"""## 1 Image Classification using SVM

"""

#loading test and training datasets and labels
train_images = np.load(path+'flower_subset.npz')['train_images']
train_labels = np.load(path+'flower_subset.npz')['train_labels']
test_images = np.load(path+'flower_subset.npz')['test_images']
test_labels = np.load(path+'flower_subset.npz')['test_labels']

#resizing test and training image to 64x64 and converting to int
img_size = (64, 64) # h x w in pixels
train_set = []
for i in range(train_images.shape[0]):
  train_set.append(cv2.resize(train_images[i],(img_size)))
test_set = []
for i in range(test_images.shape[0]):
  test_set.append(cv2.resize(test_images[i],(img_size)))
train_set = np.array(train_set)*255
test_set = np.array(test_set)*255

#Parameters for HoG features
cell_size = (8, 8)  # h x w in pixels
block_size = (4, 4)  # h x w in cells
nbins = 4  # number of orientation bins

#Creating HoG Descriptor Object
hog = cv2.HOGDescriptor(_winSize=(img_size[1] // cell_size[1] * cell_size[1],
                                  img_size[0] // cell_size[0] * cell_size[0]),
                        _blockSize=(block_size[1] * cell_size[1],
                                    block_size[0] * cell_size[0]),
                        _blockStride=(cell_size[1], cell_size[0]),
                        _cellSize=(cell_size[1], cell_size[0]),
                        _nbins=nbins)


def HoG_list(data_set):
  '''
  Params:
  data_set : list of images
  Returns : HoG features for data set of images
  '''
  features = []
  for i in range(data_set.shape[0]):
    features.append(hog.compute(data_set[i].astype(np.uint8)))
  #Return array of 1600 features for each image
  return np.array(features)[:, :, 0]


train_features = HoG_list(train_set)
print('HoG list for training features is composed of {} feature vectors of length {}.'.format(train_features.shape[0], train_features.shape[1]))
test_features = HoG_list(test_set)
print('HoG list for test features is composed of {} feature vectors of length {}.'.format(test_features.shape[0], test_features.shape[1]))

#Fit a non-linear SVM classifier (use RBF kernel with gamma=‘auto’ and C=1)
#on the features and the class labels of the training images
clf = svm.SVC(gamma='auto', C=1) 
clf.fit(train_features, train_labels)
#Predict labels of the test images by feeding the test features
#to the trained classifier and calculate classification accuracy.
svm_prediction = clf.predict(test_features)
print('Support Vector Machine Results')
print("Predicted Label:", svm_prediction )
print("Actual Label:", test_labels)
count = 0
for predict, actual in zip(svm_prediction, test_labels):
  if predict == actual: 
      count += 1
print('SVM performance on test set with C={}, gamma={}: {}% \n'.format(1, 'auto', count/len(test_labels)*100))

#Tune values of hyperparameters ‘gamma’ and ‘C’ to achieve test
#accuracy greater than 25%.
#Obtained parameters for good performance by trial and error 
gamma = 1/100
C = 100
clf = svm.SVC(gamma=gamma, C=C) 
clf.fit(train_features, train_labels)
svm_prediction = clf.predict(test_features)
print('Support Vector Machine Results')
print("Predicted Label:", svm_prediction )
print("Actual Label:", test_labels)
count = 0
for predict, actual in zip(svm_prediction, test_labels):
  if predict == actual: 
      count += 1
print('SVM performance on test set with C={}, gamma={}: {}% \n'.format(C, gamma, count/len(test_labels)*100))

#Fit a Random Forest(RF) classifier (set n estimators=10, max depth=5 and criterion=‘entropy’)
#on the features and the class labels of the training images.
clf = RandomForestClassifier(n_estimators=10, max_depth=5, criterion='entropy')
clf.fit(train_features, train_labels)
#Predict labels of the test images by feeding the test features to the
#trained classifier and calculate classification accuracy.
rf_prediction = clf.predict(test_features)
print('Random Forest Classifier Results')
print("Predicted Label:", rf_prediction)
print("Actual Label:", test_labels)
count = 0
for predict, actual in zip(rf_prediction, test_labels):
  if predict == actual: 
      count += 1
print('RF performance on test set with {} estimators and max depth of {}: {}% \n'.format(10, 5, count/len(test_labels)*100))

#Tune values of hyperparameters ‘n estimators’ and ‘max depth’ to achieve
#test accuracy greater than 25%.
#Obtained parameters for good performance by trial and error 
estimators = 100
depth = 10
clf = RandomForestClassifier(n_estimators=estimators, max_depth=depth, criterion='entropy')
clf.fit(train_features, train_labels)
rf_prediction = clf.predict(test_features)
print('Random Forest Classifier Results')
print("Predicted Label:", rf_prediction)
print("Actual Label:", test_labels)
count = 0
for predict, actual in zip(rf_prediction, test_labels):
  if predict == actual: 
      count += 1
print('RF performance on test set with {} estimators and max depth of {}: {}%'.format(estimators, depth, count/len(test_labels)*100))

"""Compare results of SVM and RF classifiers. Which one provides better results? Experiment training both classifiers with a range of random stats and measure classification accuracy of the test set. Which classifier is more stable or robust to the change in random state? """

C = [1,10,100]
gamma = [1, 0.1, 0.01]
random_state = [0,10,30,40]

for c in C:
  for g in gamma:
    for r in random_state:
      clf = svm.SVC(gamma=g, C=c,random_state=r) 
      clf.fit(train_features, train_labels)
      svm_prediction = clf.predict(test_features)
      count = 0
      for predict, actual in zip(svm_prediction, test_labels):
        if predict == actual: 
            count += 1
      print('SVM performance on test set with C={}, gamma={}, random state={}: {}%'.format(c, g, r, count/len(test_labels)*100))
    print('\n')

#Note: running time is very long for training with range of hyperparameters
# so, results are posted in section 1 of the Read Me.

estimators = [1,10,100]
depths = [5,10,15]
random = [0,10,30,40]
for n in estimators:
  for d in depths: 
    for r in random:
      clf = RandomForestClassifier(n_estimators=n, max_depth=d, criterion='entropy', random_state = r)
      clf.fit(train_features, train_labels)
      rf_prediction = clf.predict(test_features)
      count = 0
      for predict, actual in zip(rf_prediction, test_labels):
        if predict == actual: 
            count += 1
      print('RF performance on test set with {} estimators, max depth of {}, and random state of {}: {}%'.format(n, d, r, count/len(test_labels)*100))
    print('\n')

#Note: running time is very long for training with range of hyperparameters
# so, results are posted in section 2 of the Read Me.

"""The hyper parameters were adjusted to give the best performance by trial and error, and the models were retrained with the new hyper parameters. With the best hyperparameters, SVM yields higher performance at 61% with C=100 and gamma = 1/100. 

The SVM and RF were then retrained with a range of random states for a range of hyperparameters. The random forest classifier results much more volatile to random states, as shown by the results – when hyperparameters were held constant, the performance could fluctuate by as much as 11%, or 6% on average. This could however be an advantage of RF - if the random state variable is chosen well, then its performance could be greater than that of the SVM. As it takes long to train each Random Forest Classfier over the range of hyperparameters and random states, screenshots of a set of results can be found in Section 2 of the Read Me. 

Conversely, the SVM model is very robust to random states over the range of parameters it was tested over, as shown by the results. A set of results can be found in Section 1 of the Read Me. The support vector machine is robust as the results  do not vary through the range of hyperparameters due to changes in random state. 
"""